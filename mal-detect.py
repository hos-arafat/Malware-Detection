"""
author: Hossam Arafat
Matricola: 1803850

Parts of this code were developed with Karim Kamal Ghonim
Help was given from Ibis Prevedello and Aurelien Bec
"""
import csv
import os
import numpy as np
import pandas as pd
import time
from random import shuffle
from matplotlib import pyplot as plt


import sklearn
from sklearn.naive_bayes import BernoulliNB
from sklearn.cross_validation import train_test_split
from sklearn import svm
from sklearn.metrics import classification_report

from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import f1_score


malwares = list()
benigns = list()

features = list()
feature_values = list()

Available_Feats = []
x = []
y = []
X = list()

data_path = r"E:\Datasets\drebin\drebin\feature_vectors1\\"
# data_path = r"E:\Masters\First_Semester\Machine_Learning\Homeworks\BonusHW\Small_Dataset"
path_to_csv = r"E:\Datasets\drebin\drebin\\"
features_considered = ["url", "permissions"]

#Data_Path = input("Enter the Path to the Data set: ")
#Path_to_csv = input("Enter the path to the CSV file: ")

try:
    dataset_files = os.listdir(data_path)
    # print(files)
    print(" Building Y vector of 0s...")
except FileNotFoundError:
    print("Please run the program again with a valid path.")
    exit()

try:
    with open(path_to_csv + "\sha256_family.csv") as csvfile:
        csvReader = csv.reader(csvfile, delimiter=',')
        malwares_csv = list(csvReader)
        #y = [0] * len(malwares_csv)
        # print(Malware_Files)
        for row in malwares_csv:
            if row[0] == 'sha256':
                pass
            else:
                # print(row)
                malwares.append(row[0])
                if row[0] in dataset_files:
                    #print("malware found")
                    #print("index of malware in files is", )
                    #print(y)
                    print("Setting the Malware files target values to 1s")
                    #y[malwares_csv.index(row)] = 1
except FileNotFoundError:
    print("CSV file not found, please check your path.")


# print(len(malwares))
#print(y)
# print(malwares)
#print(y.count(0))

Y = np.asarray(y)
#print("Y's shape ", Y.shape)
#print(np.count_nonzero(Y))
Y = Y.reshape((Y.shape[0], 1))
#print("Y's shape now is ", Y.shape)

virusdf = pd.DataFrame(malwares, columns=["File"])
virusdf["Classification"] = "Malware"
virusdf.to_csv(r"E:\Masters\First_Semester\Machine_Learning\Homeworks\BonusHW\Final_Trial\Malwares_Found.txt", index=False)

benignsdf = pd.DataFrame(benigns, columns=["File"])
benignsdf["Classification"] = "Benign"
benignsdf.to_csv(r"E:\Masters\First_Semester\Machine_Learning\Homeworks\BonusHW\Final_Trial\Benigns_Found.txt", index=False)

result = pd.concat([benignsdf, virusdf], ignore_index=True)
result.to_csv(r"E:\Masters\First_Semester\Machine_Learning\Homeworks\BonusHW\Final_Trial\Result.txt", index=False)

"""
for i in dataset_files:
    with open(data_path + i, 'r') as f:
        for line in f:
            line = line.rstrip()
            line = line.split('::')
            print("File Number: ", i)
            if os.stat(data_path + i).st_size > 0:
                #features.append(line[0])
                #feature_values.append(line[1])
                #print(line[0])
                # features[line[0]] = features.get(line[0], 0) + 1
                # feature_values[line[1]] = feature_values.get(line[1], 0) + 1
            else:
                continue
                # 76e91e1f9cc3422c333e51b65bb98dd50d00f1f45a15d2008807b06c125e651a
# print(features)
# print(feature_values)

#"""

Sets_On = ['permission', 'url', 'feature']

# Prepare features available in all datasets
for i in dataset_files:

    # Temporary lists of features and their corresponding set for each file
    File_Feats = []
    File_Sets = []

    with open(data_path + i, 'r') as f:

        f_content = f.read().splitlines()

    for row in f_content:
        if row.split('::')[0] in Sets_On:
            File_Sets.append(row.split('::')[0])

            File_Feats.append(row.split('::')[1])

    for fe in File_Feats:
        if fe not in Available_Feats:
            Available_Feats.append(fe)

# Prepare X, Y and feature vector for each file

for file in dataset_files:

    # Temporary list of features
    Ap_Feat_List = []

    # Construct vector of zeros for each file
    File_feat_vector = [0] * len(Available_Feats)

    label = 0

    if file in malwares:
        label = 1

    with open(data_path + '/' + file, 'r') as f:
        f_content = f.read().splitlines()

    for row in f_content:
        if row.split('::')[0] in Sets_On:
            Ap_Feat_List.append(row.split('::')[1])

    for fe in Ap_Feat_List:
        if fe in Available_Feats:
            File_feat_vector[Available_Feats.index(fe)] = 1

    x.append(File_feat_vector)

    y.append(label)

X_Num = np.asarray(x)
Y_Num = np.asarray(y)

X_train, X_test, Y_train, Y_test = train_test_split(X_Num, Y_Num, test_size=.2, random_state=42)

# ------ NB -------
bernNB = BernoulliNB()

t = time.time()
bernNB.fit(X_train, Y_train)
t2 = time.time()

print(round(t2 - t, 2), 'Seconds to train Naive Bayes...')

t = time.time()
Y_Predict_NB = bernNB.predict(X_test)
t2 = time.time()

Y_Expect_NB = Y_test
# Number of examples
Y_Length = len(Y_Expect_NB)

print(round(t2 - t, 2), 'Seconds to predict Naive Bayes...')

print()
print("NB SKLEARN METRICS")
print("NB Accuracy Score")
print(round((accuracy_score(Y_Expect_NB, Y_Predict_NB)) * 100, 2), '%')
print("NB Precision Score")
print(round((precision_score(Y_Expect_NB, Y_Predict_NB)) * 100, 2), '%')
print("NB Recall Score")
print(round((recall_score(Y_Expect_NB, Y_Predict_NB)) * 100, 2), '%')
print("NB F1 Score")
print(round((f1_score(Y_Expect_NB, Y_Predict_NB)) * 100, 2), '%')
print()

# NB Metrics
print("NB METRICS")
# Calculate True Positives
True_Positive = sum([Y_Expect_NB[i] == Y_Predict_NB[i] for i in range(Y_Length)])
print('True Positive:', True_Positive)
# Calculate False Positives
False_Positive = sum([not (Y_Expect_NB[i]) == Y_Predict_NB[i] for i in range(Y_Length)])
print('False Positive:', False_Positive)
# Calculate False Negative
False_Negative = sum([Y_Expect_NB[i] and not (Y_Predict_NB[i]) for i in range(Y_Length)])
print('False Negative:', False_Negative)
# Calculate True Negatives
True_Negative = sum([not (Y_Expect_NB[i]) and not (Y_Predict_NB[i]) for i in range(Y_Length)])
print('True Negative:', True_Negative)
# Calculate Precision
Precision = True_Positive / (True_Positive + False_Positive)
print('Precision:', round(Precision * 100, 2), '%')
# Calculate Recall
Recall = True_Positive / (True_Positive + False_Negative)
print('Recall:', round(Recall * 100, 2), '%')
# Calculate False Positive Rate
False_Positive_Rate = False_Positive / (False_Positive + True_Negative)
print('False positive rate:', round(False_Positive_Rate * 100, 2), '%')
# Calculate Accuracy
Accuracy = (True_Positive + True_Negative) / (True_Positive + False_Negative + True_Negative + False_Positive)
print('Accuracy:', round(Accuracy * 100, 2), '%')
# Calculate F1 Measure
F_Measure = 2 * (Precision * Recall) / (Precision + Recall)
print('F-measure:', round(F_Measure * 100, 2), '%')
print()
print()

# ------ SVM -------
svc = svm.LinearSVC()

t = time.time()
svc.fit(X_train, Y_train)

t2 = time.time()
print(round(t2 - t, 2), 'Seconds to train SVM...')

Y_Expect_SVM = Y_test
# Number of examples
Y_Length = len(Y_Expect_SVM)

t = time.time()
Y_Predict_SVM = svc.predict(X_test)
t2 = time.time()

print(round(t2 - t, 2), 'Seconds to predict SVM...')
print()

print("SVM SKLEARN METRICS")
print("SVM Accuracy Score")
print(round((accuracy_score(Y_Expect_SVM, Y_Predict_SVM)) * 100, 2), '%')
print("SVM Precision Score")
print(round((precision_score(Y_Expect_SVM, Y_Predict_SVM)) * 100, 2), '%')
print("SVM Recall Score")
print(round((recall_score(Y_Expect_SVM, Y_Predict_SVM)) * 100, 2), '%')
print("SVM F1 Score")
print(round((f1_score(Y_Expect_SVM, Y_Predict_SVM)) * 100, 2), '%')
print()

# SVM Metrics
print("SVM METRICS")
# Calculate True Positives
True_Positive = sum([Y_Expect_SVM[i] and Y_Predict_SVM[i] for i in range(Y_Length)])
print('True Positive:', True_Positive)
# Calculate False Positives
False_Positive = sum([not (Y_Expect_SVM[i]) and Y_Predict_SVM[i] for i in range(Y_Length)])
print('False Positive:', False_Positive)
# Calculate False Negative
False_Negative = sum([Y_Expect_SVM[i] and not (Y_Predict_SVM[i]) for i in range(Y_Length)])
print('False Negative:', False_Negative)
# Calculate True Negatives
True_Negative = sum([not (Y_Expect_SVM[i]) and not (Y_Predict_SVM[i]) for i in range(Y_Length)])
print('True Negative:', True_Negative)
# Calculate Precision
Precision = True_Positive / (True_Positive + False_Positive)
print('Precision:', round(Precision * 100, 2), '%')
# Calculate Recall
Recall = True_Positive / (True_Positive + False_Negative)
print('Recall:', round(Recall * 100, 2), '%')
# Calculate False Positive Rate
False_Positive_Rate = False_Positive / (False_Positive + True_Negative)
print('False positive rate:', round(False_Positive_Rate * 100, 2), '%')
# Calculate Accuracy
Accuracy = (True_Positive + True_Negative) / (True_Positive + False_Negative + True_Negative + False_Positive)
print('Accuracy:', round(Accuracy * 100, 2), '%')
# Calculate F1 Measure
F_Measure = 2 * (Precision * Recall) / (Precision + Recall)
print('F-measure:', round(F_Measure * 100, 2), '%')



# """